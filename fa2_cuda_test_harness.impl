// TESTING
#include <iostream>
#include <string>
#include <fstream>
#include <chrono>

#define BLOCK_SIZE (32 * NUM_WORKERS)

#define CudaCheckError() __cudaCheckError(__FILE__, __LINE__)
inline void __cudaCheckError(const char *file, const int line)
{
    cudaError err = cudaGetLastError();
    if (cudaSuccess != err)
    {
        fprintf(stderr, "cudaCheckError() failed at %s:%i : %s\n",
                file, line, cudaGetErrorString(err));
        exit(-1);
    }
    // More careful checking. However, this will affect performance.
    // Comment away if needed.
    err = cudaDeviceSynchronize();
    if (cudaSuccess != err)
    {
        fprintf(stderr, "cudaCheckError() with sync failed at %s:%i : %s\n",
                file, line, cudaGetErrorString(err));
        exit(-1);
    }
}

// N H D
void seqFillMatrix(float *mat, int n, int h, int d, float factor)
{
    for (int _h = 0; _h < h; _h++)
    {
        float fillValue = 0.0f;
        for (int _n = 0; _n < n; _n++)
        {
            for (int _d = 0; _d < d; _d++)
            {
                mat[(_n * h * d) + (_h * d) + _d] = fillValue;
                fillValue += factor;
            }
        }
    }
}

constexpr uint64_t ATTN_FLOPS =
    2llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N * ATTN_D + // Q * K^T: 2BHNND (multiply-add)
    4llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N +          // Softmax: 2BHNN (exp and divide, plus flash-attn bookkeeping)
    2llu * ATTN_B * ATTN_H * ATTN_N * ATTN_N * ATTN_D;  // (Q * K^T) * V: 2BHNND (multiply-add)

int main(int argc, char **argv)
{
    constexpr int TOTAL_ELEMENTS = ATTN_B * ATTN_H * ATTN_N * ATTN_D;
    constexpr int TOTAL_UNIQUE_ELEMENTS = ATTN_H * ATTN_N * ATTN_D;

    // QKVO and o_ref on host
    float *q = new float[TOTAL_ELEMENTS];
    float *k = new float[TOTAL_ELEMENTS];
    float *v = new float[TOTAL_ELEMENTS];
    float *o = new float[TOTAL_ELEMENTS];
    float *o_ref = new float[TOTAL_UNIQUE_ELEMENTS];

    // QKVO as bfloat16
    bf16 *q_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *k_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *v_bf = new bf16[TOTAL_ELEMENTS];
    bf16 *o_bf = new bf16[TOTAL_ELEMENTS];

    std::ifstream infile(argv[1]);

    std::cout << "Starting to enter!" << std::endl;

    // Copy in HND elements(so every element in the batch will be the same basically)
    for (int i = 0; i < TOTAL_ELEMENTS / ATTN_B; i++)
        infile >> q[i];
    std::cout << "Finished loading Q" << std::endl;
    for (int i = 0; i < TOTAL_ELEMENTS / ATTN_B; i++)
        infile >> k[i];
    std::cout << "Finished loading K" << std::endl;
    for (int i = 0; i < TOTAL_ELEMENTS / ATTN_B; i++)
        infile >> v[i];
    std::cout << "Finished loading V" << std::endl;
    for (int i = 0; i < TOTAL_ELEMENTS / ATTN_B; i++)
        infile >> o_ref[i];
    std::cout << "Finished loading O_REF" << std::endl;

    std::cout << "Finished loading file from " << argv[1] << "!" << std::endl;

    // seqFillMatrix(q, ATTN_N, ATTN_H, ATTN_D, 0.001f);
    // seqFillMatrix(k, ATTN_N, ATTN_H, ATTN_D, 0.001f);
    // seqFillMatrix(v, ATTN_N, ATTN_H, ATTN_D, 0.001f);

    // Convert elements to bfloat16, and replicate over B
    for (int i = 0; i < TOTAL_ELEMENTS; i++)
    {
        q_bf[i] = __float2bfloat16(q[i % (TOTAL_ELEMENTS / ATTN_B)]);
        k_bf[i] = __float2bfloat16(k[i % (TOTAL_ELEMENTS / ATTN_B)]);
        v_bf[i] = __float2bfloat16(v[i % (TOTAL_ELEMENTS / ATTN_B)]);
    }

    // allocate qkvo on device and copy data over
    bf16 *d_q, *d_k, *d_v, *d_o;
    cudaMalloc(&d_q, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_k, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_v, TOTAL_ELEMENTS * sizeof(bf16));
    cudaMalloc(&d_o, TOTAL_ELEMENTS * sizeof(bf16));

    cudaMemcpy(d_q, q_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_k, k_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);
    cudaMemcpy(d_v, v_bf, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyHostToDevice);

    unsigned long mem_size = (100000) / 2; // define KITTENS_4090
    std::cout << "Max shared memory size: " << mem_size << std::endl;

    // set the attention kerne's max memory size for the extern
    cudaFuncSetAttribute(
        attention_cuda_4090<ATTN_D>,
        cudaFuncAttributeMaxDynamicSharedMemorySize,
        mem_size);

    cudaDeviceSynchronize();

    std::cout << "Starting kernel\n";

    // grid is h, b and then ceil_div(attn_n(1024), ROWS per block * num workers) since each block will calculate ROWS * num_workers
    dim3 grid((ATTN_N + ROWS * NUM_WORKERS - 1) / (ROWS * NUM_WORKERS), ATTN_H, ATTN_B);
    const auto start = std::chrono::high_resolution_clock::now();
    for (int i = 0; i < ITER; i++)
    {
        attention_cuda_4090<<<grid, BLOCK_SIZE, mem_size>>>(d_q, d_k, d_v, d_o);
    }
    cudaDeviceSynchronize();
    const auto finish = std::chrono::high_resolution_clock::now();
    CudaCheckError();
    std::cout << "Finished kernel\n";

    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess)
    {
        std::cout << "CUDA error: " << cudaGetErrorString(err) << std::endl;
        return 1;
    }

    // check correctness
    cudaMemcpy(o_bf, d_o, TOTAL_ELEMENTS * sizeof(bf16), cudaMemcpyDeviceToHost);
    for (int i = 0; i < TOTAL_ELEMENTS; i++)
    {
        o[i] = __bfloat162float(o_bf[i]);
    }
    cudaDeviceSynchronize();

    int print_start_idx = 1048576; // 1659457;
    std::cout << "out: ";
    for (int i = print_start_idx; i < print_start_idx + 8; ++i)
    {
        // std::cout << __bfloat162float(o_bf[i]) << " ";
        std::cout << o[i] << " ";
    }
    std::cout << std::endl;
    std::cout << "ref: ";
    for (int i = print_start_idx; i < print_start_idx + 8; ++i)
    {
        std::cout << o_ref[i % (TOTAL_ELEMENTS / ATTN_B)] << " ";
    }
    std::cout << std::endl;

    // More error checking than usual
    bool good = true;
    float total_diff = 0;
    float max_error = 0;
    float max_error_ref = 0;
    float max_error_o = 0;
    int max_error_ref_idx = 0;

    float large_tolerable_error = 0.01;
    bool print_large_error = true;

    for (int i = 0; i < TOTAL_ELEMENTS; i++)
    {
        float diff = o[i] - o_ref[i % (TOTAL_ELEMENTS / ATTN_B)];
        if (abs(diff) > 0.01 || isnan(diff))
        {
            good = false;
        }
        if (abs(diff) > max_error) {
            max_error = abs(diff);
            max_error_ref = o_ref[i % (TOTAL_ELEMENTS / ATTN_B)];
            max_error_ref_idx = i;
            max_error_o = o[i];
        }
        if (abs(diff) > large_tolerable_error && print_large_error) {
            printf("LARGE ERROR at idx %d, (r%f - o%f) = %f\n", i, o_ref[i], o[i], o_ref[i] - o[i]);
            print_large_error = false;
        }
        total_diff += abs(diff);
    }
    std::cout << "Average diff: " << total_diff / TOTAL_ELEMENTS << std::endl;
    printf("Max relative diff: (r%f - o%f) ==> %f at idx %d\n", max_error_ref, max_error_o, max_error, max_error_ref_idx);
    // end error checking

    // Timing this way yields same results as using cudaEventRecord
    std::cout << "Average diff: " << total_diff / TOTAL_ELEMENTS << std::endl;
    printf("Max diff: %f - %f = %f\n", max_error_ref, max_error_o, max_error);
    std::cout << "Average execution time: " << std::chrono::duration_cast<std::chrono::microseconds>(finish - start).count() / ITER << " us" << std::endl;
    if (good)
        std::cout << "Correct :)\n";
    else
        std::cout << "Incorrect :(\n";
    // Compute and print average TFLOPs achieved
    double avg_time_s = (double)(std::chrono::duration_cast<std::chrono::microseconds>(finish - start).count()) / (ITER * 1e6);
    double avg_tflops = (ATTN_FLOPS / avg_time_s) / 1e12;
    std::cout << "Efficiency: " << avg_tflops << " TFLOPS\n\n\n"
              << std::endl;

    cudaFree(d_q);
    cudaFree(d_k);
    cudaFree(d_v);
    cudaFree(d_o);

    delete[] q, k, v, o, o_ref;
    delete[] q_bf, k_bf, v_bf, o_bf;

    return 0;
}